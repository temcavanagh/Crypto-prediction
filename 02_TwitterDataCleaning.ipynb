{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Twitter Data Cleaning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "from time import sleep\n",
                "import pandas as pd\n",
                "import re\n",
                "from tqdm import tnrange, tqdm_notebook, tqdm\n",
                "\n",
                "PRICE_FOLDER    = \"data/price/\" \n",
                "TWITTER_FOLDER  = \"data/twitter/\"\n",
                "tweets_raw_file = './data/twitter/bitcoin_tweets_raw.csv'\n",
                "tweets_clean_file = './data/twitter/bitcoin_tweets_clean.csv'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read in data\n",
                "d = pd.read_csv(tweets_raw_file)\n",
                "# Drop duplicate rows to manage dulpicate headers\n",
                "d = d[d.ID !='ID']\n",
                "d = d.reset_index(drop=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 4500/4500 [00:04<00:00, 917.42it/s] \n",
                        "100%|██████████| 4051/4051 [00:02<00:00, 1990.89it/s]\n"
                    ]
                }
            ],
            "source": [
                "for i, s in enumerate(tqdm(d['Tweets'])):\n",
                "    text = d.loc[i, 'Tweets']\n",
                "    text = text.replace(\"#\", \"\")\n",
                "    text = text.replace(\"@\", \"\")\n",
                "    text = re.sub('https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+', '', text, flags=re.MULTILINE)\n",
                "    text = re.sub('@\\\\w+ *', '', text, flags=re.MULTILINE)\n",
                "    d.loc[i, 'Tweets'] = text\n",
                "\n",
                "# Remove keywords from dataframe\n",
                "to_remove = [\"Airdrop\", \"airdrop\", \"freebitcoin\", \"freebtc\"]\n",
                "d = d[~d.Tweets.str.contains(\"|\".join(to_remove))]\n",
                "d = d.reset_index(drop=True)\n",
                "\n",
                "# Manage dataframe times\n",
                "d['CreatedAt'] = pd.to_datetime(d['CreatedAt'])\n",
                "twitter_hr = []\n",
                "twitter_next_hr = []\n",
                "for i, s in enumerate(tqdm(d['CreatedAt'])):\n",
                "    t = s.floor(freq='H')\n",
                "    n = s.ceil(freq='H')\n",
                "    twitter_hr.append(t)\n",
                "    twitter_next_hr.append(n)\n",
                "d['Hour'] = twitter_hr\n",
                "d['NextHour'] = twitter_next_hr"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read clean file\n",
                "try:\n",
                "    clean_df = pd.read_csv(tweets_clean_file)\n",
                "except pd.io.common.EmptyDataError:\n",
                "    clean_df = pd.DataFrame()\n",
                "# Merge raw and clean\n",
                "clean_df_updated = pd.concat([clean_df, d])\n",
                "# Drop duplicates\n",
                "clean_df_updated = clean_df_updated.drop_duplicates(subset=['Tweets'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Write clean csv\n",
                "f = open(tweets_clean_file, 'a+', encoding='utf-8')\n",
                "clean_df_updated.to_csv(f, header=True, encoding='utf-8',index=False)\n",
                "f.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Update and clear raw csv\n",
                "r = open(tweets_raw_file, 'w+', encoding='utf-8')\n",
                "r.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Twitter data cleaned sucessfully\n"
                    ]
                }
            ],
            "source": [
                "print('Twitter data cleaned sucessfully')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Write script"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[NbConvertApp] Converting notebook 02_TwitterDataCleaning.ipynb to script\n",
                        "[NbConvertApp] Writing 2488 bytes to 02_TwitterDataCleaning.py\n"
                    ]
                }
            ],
            "source": [
                "!jupyter nbconvert --to script --no-prompt 02_TwitterDataCleaning.ipynb"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
        },
        "kernelspec": {
            "display_name": "Python 3.8.3 64-bit ('base': conda)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.3"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
