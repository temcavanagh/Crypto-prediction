{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter extraction\n",
    "\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRICE_FOLDER    = \"data/price/\"\n",
    "TWITTER_FOLDER  = \"data/twitter/\"\n",
    "tweets_raw_file = './data/twitter/bitcoin_tweets_raw.csv'\n",
    "tweets_clean_file = './data/twitter/bitcoin_tweets_clean.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieve the tweets from Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Tweepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "import tweepy\n",
    "\n",
    "required = {'numpy','pandas','tweepy'} \n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    # implement pip as a subprocess:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install',*missing])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 OAuth2 Authentication (*app* authentication)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= # Removed\n",
    "consumer_secret= # Removed\n",
    "access_token= # Removed\n",
    "access_token_secret= # Removed\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Query the twitter API\n",
    "Here we query the twitter API to get the latest tweets about bitcoin. Then we transform it to store only the useful data inside a Pandas Dataframe.\n",
    "\n",
    "The following fields are retrieved from the response:\n",
    "\n",
    "- **id** (int) : unique identifier of the tweet\n",
    "- **text** (string) : UTF-8 textual content of the tweet, max 140 chars\n",
    "- user\n",
    "  - **name** (string) : twitter's pseudo of the user\n",
    "  - **followers_count** (int) : Number of followers the user has\n",
    "- **retweet_count** (int) : Number of times the tweet has been retweeted\n",
    "- **favorite_count** (int) : Number of likes\n",
    "- **created_at** (datetime) : creation date and time of the tweet\n",
    "\n",
    "Also, we wanted to retrieve the following fields but it is not possible with the standard free API, Enteprise or premium is needed (https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object.html):\n",
    "\n",
    "- reply_count (int) : Number of times the Tweet has been replied to\n",
    "\n",
    "The pandas package must be installed using *pip install pandas* from the command line.\n",
    "\n",
    "We used the search opertators that are explained here (https://lifehacker.com/search-twitter-more-efficiently-with-these-search-opera-1598165519) to not only search by hashtag but also the tweets that contain the currency name or that have the hashtag with the currency's abreviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import json\n",
    "import pandas as pd\n",
    "import io\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/twitter/bitcoin_tweets_raw.csv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_raw_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "now = datetime.today().now()\n",
    "prev_hr = now-timedelta(hours=1)\n",
    "now = now.strftime(\"%Y-%m-%d, %H:%M:%S\")\n",
    "prev_hr = prev_hr.strftime(\"%Y-%m-%d, %H:%M:%S\")\n",
    "now\n",
    "prev_hr\n",
    "\n",
    "prev_test = datetime(2021, 9, 9, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved tweets, waiting for 1 hour until next query\n"
     ]
    }
   ],
   "source": [
    "number_of_tweets = 100\n",
    "data = {\"statuses\": []}\n",
    "next_id = \"\" #\"1147236962945961984\"\n",
    "since_id= ''\n",
    "text_query = \"Bitcoin -filter:retweets\"\n",
    "language = \"en\"\n",
    "tweets = []\n",
    "likes = []\n",
    "retweets = []\n",
    "followers = []\n",
    "time = []\n",
    "ID = []\n",
    "\n",
    "##\n",
    "file_exists = os.path.isfile(tweets_raw_file)\n",
    "\n",
    "with open(tweets_raw_file,\"a+\", encoding='utf-8') as file_:\n",
    "    \n",
    "    #file_.write(\"Tweets,Likes,CreatedAt\\n\") Creation date should go here?\n",
    "\n",
    "    while(True):\n",
    "        \n",
    "        for i in tweepy.Cursor(api.search, q=text_query, result_type=\"recent\", lang=language, tweet_mode=\"extended\").items(number_of_tweets):\n",
    "            ID.append(i.id)\n",
    "            tweets.append(i.full_text)\n",
    "            likes.append(i.favorite_count)\n",
    "            retweets.append(i.retweet_count)\n",
    "            followers.append(i.user.followers_count)\n",
    "            time.append(i.created_at)\n",
    "        \n",
    "        last_size = 0\n",
    "\n",
    "        print('Retrieved tweets, waiting for 1 hour until next query'.format(len(data[\"statuses\"])))\n",
    "        df = pd.DataFrame({'ID':ID, 'Tweets':tweets, 'Likes':likes, 'Retweets':retweets, 'Followers':followers, 'CreatedAt':time})\n",
    "        df.to_csv(file_, mode='a', encoding='utf-8',index=True,header=True)\n",
    "        if last_size + 1 == len(data[\"statuses\"]):\n",
    "            print('No more new tweets, stopping...')\n",
    "            break\n",
    "        data[\"statuses\"] = []\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 01_TwitterExtraction.ipynb to script\n",
      "[NbConvertApp] Writing 5015 bytes to 01_TwitterExtraction.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script --no-prompt 01_TwitterExtraction.ipynb"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
